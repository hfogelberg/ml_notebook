{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Processing and interpreting images with ai/ml. The technique is used in self driving cars etc and was pionered by Yann Lacun.\n",
    "<p>\n",
    "Internally the computer only works by analyzing the individual pixels in the image. A black and white image is 2D and a color image 3D. In a black and white picture the greyness of each pixel is given a value of 0-255. In a color image there are three layers; R, G and B.\n",
    "<br>\n",
    "![How coumputer sees image](img/picture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 1: Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution finds features in an image and put through a feature map. Convolution retains the spatial relationship between pixels. As a side effect it also reduces the complexity of the image and leads to faster processing.\n",
    "\n",
    "![Convolution](img/convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1b: ReLU (Rectified Lineat Units)\n",
    "The rectifier function is applied to each convolution layer in the output from convolution. This decreases the linearity. The reason you want that is because images are non linear: you want to distinguish between specific areas in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pooling\n",
    "\n",
    "How can you make the computer identify different dogs in different images? The dogs may be in different parts of the image, be looking in different directions, have different body positions etc. The sollution is called spatial invariance. It doesn't care where in the image a particular feature is or if it is a bit distorted.\n",
    "<p>\n",
    "There are several different type of pooling; max pooling, average pooling, sub sampling etc. Unimportent information is removed from the image and the features are preserved. Also distortions etc will be removed. The size of the image going in to the neural net is reduced by about 75%. This speeds up the processing and reduces the risk of over fitting.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Flattening\n",
    "![flattening](img/flattening.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Full Connection\n",
    "Neural network added to the convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
